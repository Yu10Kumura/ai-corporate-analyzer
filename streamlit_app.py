#!/usr/bin/env python3
"""
ğŸ¢ ä¼æ¥­ãƒ“ã‚¸ãƒã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ  - Streamlit Webç‰ˆ
EVPæ©Ÿèƒ½ã‚’å‰Šé™¤ã—ã€ä¼æ¥­ã®ãƒ“ã‚¸ãƒã‚¹åˆ†æã«ç‰¹åŒ–ã—ãŸAIã‚·ã‚¹ãƒ†ãƒ 
"""

import streamlit as st
import os
import json
import time
import requests
from pathlib import Path
from openai import OpenAI
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from datetime import datetime, timedelta

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸ¢ ä¼æ¥­ãƒ“ã‚¸ãƒã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# è¨­å®šå®šæ•°
CONFIG = {
    'MAX_CRAWL_DEPTH': 2,
    'DATE_LIMIT_YEARS': 3,
    'MAX_SOURCES': 10,
    'USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
}

class SearchBasedIRCollector:
    """SerpAPIæ¤œç´¢ãƒ™ãƒ¼ã‚¹ã®IRæƒ…å ±åé›†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, company_name):
        self.company_name = company_name
        self.session = requests.Session()
        self.session.headers.update({'User-Agent': CONFIG['USER_AGENT']})
    
    def get_serpapi_key(self):
        """SerpAPIã‚­ãƒ¼å–å¾—ï¼ˆæœ¬ç•ªç’°å¢ƒå¯¾å¿œï¼‰"""
        # Streamlit Cloud ã®Secretsæ©Ÿèƒ½ã‚’å„ªå…ˆ
        if hasattr(st, 'secrets') and "SERPAPI_KEY" in st.secrets:
            return st.secrets["SERPAPI_KEY"]
        # ç’°å¢ƒå¤‰æ•°ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        elif os.getenv("SERPAPI_KEY"):
            return os.getenv("SERPAPI_KEY")
        else:
            st.warning("âš ï¸ SerpAPI ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚IRæ¤œç´¢æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")
            st.markdown("""
            **SerpAPIè¨­å®šæ–¹æ³•ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰:**
            - 1. https://serpapi.com ã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆï¼ˆç„¡æ–™æ æœˆ100å›ï¼‰
            - 2. Streamlit Cloud: Secretsæ©Ÿèƒ½ã§SERPAPI_KEYã‚’è¨­å®š
            - 3. ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ: ç’°å¢ƒå¤‰æ•°ã§SERPAPI_KEYã‚’è¨­å®š
            """)
            return None
    
    def search_with_serpapi(self, query, api_key):
        """SerpAPIã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢å®Ÿè¡Œ"""
        url = "https://serpapi.com/search"
        params = {
            "q": query,
            "api_key": api_key,
            "engine": "google",
            "num": 5,  # ç„¡æ–™æ ç¯€ç´„
            "hl": "ja",  # æ—¥æœ¬èª
            "gl": "jp"   # æ—¥æœ¬åœ°åŸŸ
        }
        
        try:
            response = requests.get(url, params=params, timeout=15)
            
            if response.status_code == 200:
                result = response.json()
                # ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
                if 'error' in result:
                    st.warning(f"SerpAPI Error: {result['error']}")
                    return {'error': result['error']}
                return result
            elif response.status_code == 401:
                st.error("âŒ SerpAPIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚Secretsè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return {'error': 'Invalid API Key'}
            elif response.status_code == 429:
                st.warning("âš ï¸ SerpAPIä½¿ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
                return {'error': 'Rate limit exceeded'}
            else:
                st.warning(f"SerpAPI HTTP Error: {response.status_code}")
                return {'error': f'HTTP {response.status_code}'}
                
        except requests.exceptions.Timeout:
            st.warning("âš ï¸ SerpAPIæ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            return {'error': 'Timeout'}
        except requests.exceptions.ConnectionError:
            st.warning("âš ï¸ SerpAPIã«æ¥ç¶šã§ãã¾ã›ã‚“")
            return {'error': 'Connection Error'}
        except requests.exceptions.RequestException as e:
            st.warning(f"âš ï¸ SerpAPIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}
        except Exception as e:
            st.warning(f"âš ï¸ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}
    
    def search_ir_information(self):
        """IRé–¢é€£æƒ…å ±ã‚’æ¤œç´¢ãƒ™ãƒ¼ã‚¹ã§åé›†"""
        serpapi_key = self.get_serpapi_key()
        if not serpapi_key:
            st.info("ğŸ” SerpAPIã‚­ãƒ¼ãŒæœªè¨­å®šã®ãŸã‚ã€ä¸€èˆ¬çš„ãªå…¬é–‹æƒ…å ±ã§åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™")
            return []
        
        # IRé–¢é€£æ¤œç´¢ã‚¯ã‚¨ãƒª
        search_queries = [
            f"{self.company_name} IR æŠ•è³‡å®¶å‘ã‘æƒ…å ±",
            f"{self.company_name} æ±ºç®— æ¥­ç¸¾ è²¡å‹™",
            f"{self.company_name} æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸",
            f"{self.company_name} äº‹æ¥­å ±å‘Š å¹´æ¬¡å ±å‘Šæ›¸"
        ]
        
        collected_data = []
        successful_searches = 0
        
        for query in search_queries:
            try:
                st.info(f"ğŸ” æ¤œç´¢ä¸­: {query}")
                search_results = self.search_with_serpapi(query, serpapi_key)
                
                if search_results and 'organic_results' in search_results:
                    successful_searches += 1
                    for result in search_results['organic_results'][:2]:  # ä¸Šä½2ä»¶ã®ã¿
                        url = result.get('link', '')
                        title = result.get('title', '')
                        snippet = result.get('snippet', '')
                        
                        # IRé–¢é€£URLã‹ãƒã‚§ãƒƒã‚¯
                        if self.is_ir_related_url(url, title):
                            # Webãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—
                            content = self.fetch_webpage_content(url)
                            if content:
                                collected_data.append({
                                    'url': url,
                                    'content': content[:2000],  # 2000æ–‡å­—ã¾ã§
                                    'title': title,
                                    'snippet': snippet,
                                    'search_query': query
                                })
                                st.success(f"âœ… IRæƒ…å ±ã‚’å–å¾—: {title}")
                elif search_results and 'error' in search_results:
                    st.warning(f"âš ï¸ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {search_results.get('error', 'Unknown error')}")
                else:
                    st.debug(f"æ¤œç´¢çµæœãªã—: {query}")
                
                time.sleep(1)  # APIåˆ¶é™å›é¿
                
            except requests.exceptions.Timeout:
                st.warning(f"âš ï¸ æ¤œç´¢ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {query}")
                continue
            except requests.exceptions.RequestException as e:
                st.warning(f"âš ï¸ æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                continue
            except Exception as e:
                st.warning(f"âš ï¸ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}")
                continue
        
        if collected_data:
            st.success(f"ğŸ“Š {len(collected_data)}ä»¶ã®IRæƒ…å ±ã‚’æ¤œç´¢ã§åé›†ã—ã¾ã—ãŸï¼ˆ{successful_searches}/{len(search_queries)}ä»¶ã®æ¤œç´¢ãŒæˆåŠŸï¼‰")
        elif successful_searches > 0:
            st.info("ğŸ” æ¤œç´¢ã¯æˆåŠŸã—ã¾ã—ãŸãŒã€IRé–¢é€£ã®æœ‰ç”¨ãªæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ä¸€èˆ¬çš„ãªå…¬é–‹æƒ…å ±ã§åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        else:
            st.warning("âš ï¸ æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä¸€èˆ¬çš„ãªå…¬é–‹æƒ…å ±ã§åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        
        return collected_data
    
    def is_ir_related_url(self, url, title):
        """IRé–¢é€£URLã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        ir_keywords = ['ir', 'investor', 'æŠ•è³‡å®¶', 'æ±ºç®—', 'æ¥­ç¸¾', 'è²¡å‹™', 'æœ‰ä¾¡è¨¼åˆ¸', 'å¹´æ¬¡å ±å‘Š']
        url_lower = url.lower()
        title_lower = title.lower()
        
        return any(keyword in url_lower or keyword in title_lower for keyword in ir_keywords)
    
    def fetch_webpage_content(self, url):
        """Webãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—"""
        try:
            response = self.session.get(url, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                text_content = soup.get_text()
                return ' '.join(text_content.split())
            else:
                st.debug(f"HTTP {response.status_code}: {url}")
                return None
        except requests.exceptions.Timeout:
            st.debug(f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {url}")
            return None
        except requests.exceptions.RequestException as e:
            st.debug(f"å–å¾—ã‚¨ãƒ©ãƒ¼ {url}: {str(e)}")
            return None
        except Exception as e:
            st.debug(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ {url}: {str(e)}")
            return None

class BusinessAnalyzer:
    """ä¼æ¥­ãƒ“ã‚¸ãƒã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆäº‹æ¥­åˆ†æç‰¹åŒ–ï¼‰"""
    
    def __init__(self):
        self.client = OpenAI(api_key=self._get_api_key())
        
    def _get_api_key(self):
        """APIã‚­ãƒ¼ã‚’å–å¾—"""
        # Streamlit Cloudã®å ´åˆ
        if hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
            return st.secrets["OPENAI_API_KEY"]
        
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            st.stop()
        
        return api_key
    
    def create_analysis_prompt(self, company_name, ir_data=None):
        """çµ±ä¸€ã•ã‚ŒãŸåˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆäº‹æ¥­åˆ†æã®ã¿ï¼‰"""
        
        ir_content = ""
        sources_list = []
        if ir_data:
            ir_content = "\n".join([
                f"ã€IRæƒ…å ±æºã€‘: {item['title']}\nå‡ºå…¸URL: {item['url']}\nå†…å®¹: {item['content'][:800]}...\n"
                for item in ir_data[:3]
            ])
            sources_list = [item['url'] for item in ir_data[:3]]
        
        prompt = f"""
ã‚ãªãŸã¯ä¼æ¥­ãƒ“ã‚¸ãƒã‚¹åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ä¼æ¥­ã«ã¤ã„ã¦ã€äº‹æ¥­åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æå¯¾è±¡ä¼æ¥­ã€‘: {company_name}

ã€åˆ©ç”¨å¯èƒ½ãªæƒ…å ±ã€‘:
{ir_content if ir_content else "ä¸€èˆ¬çš„ãªå…¬é–‹æƒ…å ±ã«åŸºã¥ãåˆ†æã‚’å®Ÿè¡Œ"}

ã€é‡è¦åˆ¶ç´„ã€‘:
1. äº‹æ¥­åˆ†æã®4é …ç›®ã®ã¿ã«ç‰¹åŒ–
2. æ¨æ¸¬ã®å ´åˆã¯æ˜ç¢ºã«ã€Œæ¨å®šã€ã¨è¨˜è¼‰
3. ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã€Œæƒ…å ±ä¸è¶³ã€ã¨æ˜è¨˜
4. æƒ…å ±æºãŒã‚ã‚‹å ´åˆã¯å…·ä½“çš„ãªURLå‡ºå…¸ã‚’æ˜è¨˜
5. å„åˆ†æã¯800æ–‡å­—ç¨‹åº¦ã§è©³ç´°ã«è¨˜è¿°

ã€åˆ†æé …ç›®ã€‘:
1. industry_market: æ¥­ç•Œãƒ»å¸‚å ´åˆ†æï¼ˆæ‰€å±æ¥­ç•Œã€å¸‚å ´è¦æ¨¡ã€æˆé•·æ€§ï¼‰
2. market_position: æ¥­ç•Œå†…ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆå£²ä¸Šè¦æ¨¡ã€å¸‚å ´ã‚·ã‚§ã‚¢ã€ç«¶åˆæ¯”è¼ƒï¼‰
3. differentiation: ç‹¬è‡ªæ€§ãƒ»å·®åˆ¥åŒ–è¦å› ï¼ˆæŠ€è¡“åŠ›ã€ãƒ–ãƒ©ãƒ³ãƒ‰åŠ›ã€äº‹æ¥­ãƒ¢ãƒ‡ãƒ«ï¼‰
4. business_portfolio: äº‹æ¥­ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æï¼ˆä¸»åŠ›äº‹æ¥­ã€åç›Šæ§‹é€ ã€äº‹æ¥­é ˜åŸŸï¼‰

ã€å‡ºåŠ›å½¢å¼ã€‘:
ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

{{
  "business_analysis": {{
    "industry_market": "è©³ç´°ãªæ¥­ç•Œãƒ»å¸‚å ´åˆ†æï¼ˆ800æ–‡å­—ç¨‹åº¦ï¼‰",
    "market_position": "æ¥­ç•Œå†…ãƒã‚¸ã‚·ãƒ§ãƒ³ã®åˆ†æï¼ˆ800æ–‡å­—ç¨‹åº¦ï¼‰", 
    "differentiation": "ç‹¬è‡ªæ€§ãƒ»å·®åˆ¥åŒ–è¦å› ã®åˆ†æï¼ˆ800æ–‡å­—ç¨‹åº¦ï¼‰",
    "business_portfolio": "äº‹æ¥­ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®åˆ†æï¼ˆ800æ–‡å­—ç¨‹åº¦ï¼‰"
  }},
  "analysis_metadata": {{
    "company_name": "{company_name}",
    "analysis_date": "{datetime.now().strftime('%Y-%m-%d')}",
    "data_sources": {sources_list if sources_list else ["ä¸€èˆ¬çš„ãªå…¬é–‹æƒ…å ±"]},
    "ir_sources_count": {len(sources_list) if sources_list else 0},
    "reliability_score": {90 if sources_list else 70}
  }}
}}
"""
        return prompt
    
    def analyze_company(self, company_name, company_url=None):
        """ä¼æ¥­ã®äº‹æ¥­åˆ†æã‚’å®Ÿè¡Œï¼ˆæ¤œç´¢ãƒ™ãƒ¼ã‚¹ï¼‰"""
        
        # æ¤œç´¢ãƒ™ãƒ¼ã‚¹ã§IRæƒ…å ±åé›†
        collector = SearchBasedIRCollector(company_name)
        ir_data = collector.search_ir_information()
        
        # åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        prompt = self.create_analysis_prompt(company_name, ir_data)
        
        try:
            st.info("ğŸ¤– AIåˆ†æã‚’å®Ÿè¡Œä¸­...")
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=4000
            )
            
            result_text = response.choices[0].message.content
            
            # JSONè§£æ
            try:
                # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
                json_start = result_text.find('{')
                json_end = result_text.rfind('}') + 1
                json_text = result_text[json_start:json_end]
                
                result = json.loads(json_text)
                return result
                
            except json.JSONDecodeError:
                st.error("âŒ AIå¿œç­”ã®JSONè§£æã«å¤±æ•—ã—ã¾ã—ãŸ")
                st.code(result_text)
                return None
                
        except Exception as e:
            st.error(f"âŒ AIåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def save_results(self, company_name, analysis_data):
        """åˆ†æçµæœã‚’ä¿å­˜"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"business_analysis_{company_name}_{timestamp}.json"
            
            save_data = {
                "analysis_results": analysis_data,
                "generated_at": datetime.now().isoformat(),
                "system_info": {
                    "version": "3.0_search_based",
                    "analysis_type": "business_search_focused"
                }
            }
            
            # JSONæ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã¯ç’°å¢ƒã«ã‚ˆã‚Šç•°ãªã‚‹ï¼‰
            return filename, save_data
            
        except Exception as e:
            st.warning(f"âš ï¸ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None, analysis_data

def main():
    st.title("ğŸ¢ ä¼æ¥­ãƒ“ã‚¸ãƒã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("### ä¼æ¥­ã®äº‹æ¥­æˆ¦ç•¥ãƒ»ç«¶åˆåˆ†æãƒ»å¸‚å ´ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•åˆ†æ")
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    with st.expander("â„¹ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±", expanded=False):
        st.markdown("""
        **åˆ†æå†…å®¹:**
        - ğŸ“ˆ **æ¥­ç•Œãƒ»å¸‚å ´åˆ†æ**: æ‰€å±æ¥­ç•Œã¨å¸‚å ´è¦æ¨¡ãƒ»æˆé•·æ€§
        - ğŸ† **æ¥­ç•Œå†…ãƒã‚¸ã‚·ãƒ§ãƒ³**: å£²ä¸Šè¦æ¨¡ãƒ»å¸‚å ´ã‚·ã‚§ã‚¢ãƒ»ç«¶åˆæ¯”è¼ƒ
        - â­ **ç‹¬è‡ªæ€§ãƒ»å·®åˆ¥åŒ–**: æŠ€è¡“åŠ›ãƒ»ãƒ–ãƒ©ãƒ³ãƒ‰åŠ›ãƒ»äº‹æ¥­ãƒ¢ãƒ‡ãƒ«
        - ğŸ—ï¸ **äº‹æ¥­ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª**: ä¸»åŠ›äº‹æ¥­ãƒ»åç›Šæ§‹é€ ãƒ»äº‹æ¥­é ˜åŸŸ
        
        **ç‰¹å¾´:**
        - ğŸ” SerpAPIæ¤œç´¢ãƒ™ãƒ¼ã‚¹ã®IRæƒ…å ±è‡ªå‹•åé›†
        - ğŸ“Š IRè³‡æ–™ãƒ»æ±ºç®—æƒ…å ±ãƒ»æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã‚’è‡ªå‹•æ¤œç´¢
        - ğŸ¯ äº‹æ¥­åˆ†æã«ç‰¹åŒ–ï¼ˆEVPåˆ†æã¯å»ƒæ­¢ï¼‰
        - ğŸ“ 800æ–‡å­—ã®è©³ç´°åˆ†æ
        - ğŸ“„ JSONå½¢å¼ã§ã®çµæœå‡ºåŠ›
        - ğŸ”— åé›†ã—ãŸæƒ…å ±æºã®URLå‡ºå…¸æ˜è¨˜
        """)
    
    # APIã‚­ãƒ¼è¨ºæ–­
    with st.expander("ğŸ”§ APIã‚­ãƒ¼è¨ºæ–­", expanded=False):
        if st.button("ğŸ“‹ APIã‚­ãƒ¼è¨­å®šçŠ¶æ³ã‚’ç¢ºèª"):
            # OpenAI APIã‚­ãƒ¼ç¢ºèª
            try:
                analyzer = BusinessAnalyzer()
                st.success("âœ… OpenAI APIã‚­ãƒ¼: æ­£å¸¸è¨­å®šæ¸ˆã¿")
            except:
                st.error("âŒ OpenAI APIã‚­ãƒ¼: æœªè¨­å®šã¾ãŸã¯ç„¡åŠ¹")
            
            # SerpAPIã‚­ãƒ¼ç¢ºèª
            test_collector = SearchBasedIRCollector("ãƒ†ã‚¹ãƒˆ")
            serpapi_key = test_collector.get_serpapi_key()
            if serpapi_key:
                st.success("âœ… SerpAPI ã‚­ãƒ¼: æ­£å¸¸è¨­å®šæ¸ˆã¿")
                # ç°¡å˜ãªãƒ†ã‚¹ãƒˆæ¤œç´¢
                if st.button("ğŸ” SerpAPIãƒ†ã‚¹ãƒˆæ¤œç´¢å®Ÿè¡Œ"):
                    test_result = test_collector.search_with_serpapi("ãƒˆãƒ¨ã‚¿", serpapi_key)
                    if test_result and 'error' not in test_result:
                        st.success("âœ… SerpAPI: æ¤œç´¢ãƒ†ã‚¹ãƒˆæˆåŠŸ")
                    else:
                        st.error(f"âŒ SerpAPI: æ¤œç´¢ãƒ†ã‚¹ãƒˆå¤±æ•— - {test_result.get('error', 'Unknown error')}")
            else:
                st.warning("âš ï¸ SerpAPI ã‚­ãƒ¼: æœªè¨­å®šï¼ˆæ¤œç´¢æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ï¼‰")
    
    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    with st.form("analysis_form"):
        company_name = st.text_input(
            "ğŸ¢ ä¼æ¥­å *", 
            placeholder="ä¾‹: ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šã€ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã€ãƒªã‚¯ãƒ«ãƒ¼ãƒˆ",
            help="åˆ†æå¯¾è±¡ã®ä¼æ¥­åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆæ¤œç´¢ãƒ™ãƒ¼ã‚¹ã§IRæƒ…å ±ã‚’è‡ªå‹•åé›†ã—ã¾ã™ï¼‰"
        )
        
        st.markdown("---")
        submitted = st.form_submit_button("ğŸ” äº‹æ¥­åˆ†æé–‹å§‹", type="primary", use_container_width=True)
    
    # åˆ†æå®Ÿè¡Œ
    if submitted:
        if not company_name:
            st.error("ğŸš¨ ä¼æ¥­åã¯å¿…é ˆå…¥åŠ›ã§ã™ã€‚")
            return
        
        analyzer = BusinessAnalyzer()
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("ğŸ” æ¤œç´¢ãƒ™ãƒ¼ã‚¹ã§IRæƒ…å ±ã‚’åé›†ä¸­...")
        progress_bar.progress(25)
        
        with st.spinner("ğŸ¤– AIåˆ†æä¸­... (30-60ç§’ç¨‹åº¦ãŠå¾…ã¡ãã ã•ã„)"):
            progress_bar.progress(50)
            analysis_result = analyzer.analyze_company(company_name)
            progress_bar.progress(80)
        
        if analysis_result:
            # çµæœä¿å­˜
            filename, save_data = analyzer.save_results(company_name, analysis_result)
            progress_bar.progress(100)
            status_text.text("âœ… åˆ†æå®Œäº†ï¼")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state.analysis_results = {
                "data": analysis_result,
                "company_name": company_name,
                "save_data": save_data,
                "filename": filename
            }
        else:
            progress_bar.progress(0)
            status_text.text("âŒ åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
            st.error("âŒ åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    # çµæœè¡¨ç¤º
    if 'analysis_results' in st.session_state:
        results = st.session_state.analysis_results
        analysis_data = results["data"]
        company_name = results["company_name"]
        save_data = results["save_data"]
        filename = results["filename"]
        
        st.success("ğŸ‰ äº‹æ¥­åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # åŸºæœ¬æƒ…å ±
        st.markdown("---")
        st.subheader("ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ¢ ä¼æ¥­å", company_name)
        with col2:
            st.metric("ğŸ¯ åˆ†æã‚¿ã‚¤ãƒ—", "äº‹æ¥­åˆ†æç‰¹åŒ–")
        with col3:
            metadata = analysis_data.get('analysis_metadata', {})
            st.metric("ğŸ“ˆ ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢", f"{metadata.get('reliability_score', 'N/A')}/100")
        
        st.markdown("---")
        
        # ã‚¿ãƒ–å½¢å¼ã§çµæœè¡¨ç¤º
        tab1, tab2 = st.tabs(["ğŸ† äº‹æ¥­åˆ†æçµæœ", "ğŸ“„ JSONå‡ºåŠ›"])
        
        with tab1:
            st.subheader("ğŸ† ä¼æ¥­ãƒ“ã‚¸ãƒã‚¹åˆ†æ")
            
            business_labels = {
                "industry_market": "ğŸ“ˆ æ¥­ç•Œãƒ»å¸‚å ´åˆ†æ",
                "market_position": "ğŸ† æ¥­ç•Œå†…ãƒã‚¸ã‚·ãƒ§ãƒ³",
                "differentiation": "â­ ç‹¬è‡ªæ€§ãƒ»å·®åˆ¥åŒ–è¦å› ",
                "business_portfolio": "ğŸ—ï¸ äº‹æ¥­ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æ"
            }
            
            business_data = analysis_data.get('business_analysis', {})
            if business_data:
                for key, label in business_labels.items():
                    with st.expander(label, expanded=True):
                        content = business_data.get(key, "åˆ†æãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                        st.write(content)
            else:
                st.warning("äº‹æ¥­åˆ†æãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        with tab2:
            st.subheader("ğŸ“„ JSONå½¢å¼ã®åˆ†æçµæœ")
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            json_output = json.dumps(save_data, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ’¾ JSONçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=json_output,
                file_name=f"business_analysis_{company_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
            
            # JSONè¡¨ç¤º
            st.code(json_output, language="json")
        
        # æ–°ã—ã„åˆ†æãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ æ–°ã—ã„åˆ†æã‚’é–‹å§‹"):
            if 'analysis_results' in st.session_state:
                del st.session_state.analysis_results
            st.rerun()

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown(
        """
        <div style="text-align: center; color: #666;">
            ğŸ” ä¼æ¥­ãƒ“ã‚¸ãƒã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ  v3.0 (æ¤œç´¢ç‰¹åŒ–ç‰ˆ) | Powered by OpenAI GPT-4o-mini + SerpAPI
        </div>
        """, 
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()